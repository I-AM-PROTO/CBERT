{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebe07ae1-cffc-4c70-a6b7-a0777665f97c",
   "metadata": {},
   "source": [
    "## Augmenting charater level embedding to BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5d573a-180b-43e6-b495-ec1b8c491256",
   "metadata": {},
   "source": [
    "**Char CNN already exists. Why is this special?**\n",
    "- BERT is not fully dealing with OOV(especially nonsensical ones; ones caused by typo), and character level embedding can be an effective method to do so.\n",
    "- May also be used for typo detection/fixing.\n",
    "- The masking method to train BERT was never used on character level embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15c3b41-a152-49dc-ba98-8049d2e7081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af76a30c-9334-43b6-a2c7-dd5225d3dc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocab\n",
    "id_to_char = ['<PAD>', '<CLS>', '<SEP>', '<MASK>', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '@', \\\n",
    "              '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~']\n",
    "char_to_id = {c:i for i,c in enumerate(id_to_char)}\n",
    "\n",
    "# Load preprocessed data (CBERT data preprocessing.ipynb)\n",
    "# Contains: input_ids, encoder_mask, word_idx, num_words, num_chars\n",
    "charYelp = pd.read_pickle(\"./dataset/charYelp_train\")\n",
    "input_ids = [x for x in torch.tensor(charYelp[\"input_ids\"].values.tolist())]\n",
    "encoder_mask = [x for x in torch.tensor(charYelp[\"encoder_mask\"].values.tolist())]\n",
    "\n",
    "charYelp_val = pd.read_pickle(\"./dataset/charYelp_validation\")\n",
    "#charYelp_val = pd.read_pickle(\"./dataset/charYelp_validation_medium\")\n",
    "#charYelp_val = pd.read_pickle(\"./dataset/charYelp_validation_large\")\n",
    "input_ids_val = [x for x in torch.tensor(charYelp_val[\"input_ids\"].values.tolist())]\n",
    "encoder_mask_val = [x for x in torch.tensor(charYelp_val[\"encoder_mask\"].values.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb7434b-faf6-4f82-ade4-ad95a78a8f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloader\n",
    "yelp_dataframe = list(zip(input_ids, encoder_mask))\n",
    "train_iter = DataLoader(yelp_dataframe, batch_size=48, shuffle=True, num_workers=4)\n",
    "yelp_val_dataframe = list(zip(input_ids_val, encoder_mask_val))\n",
    "val_iter = DataLoader(yelp_val_dataframe, batch_size=48, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a32bbe5-3254-4372-a377-d01ae0a8ff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_spechar = 4\n",
    "vocab_size = len(id_to_char)-num_spechar\n",
    "data_max_len = 256\n",
    "from torch.nn import ModuleList\n",
    "import copy\n",
    "\n",
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, pad_idx, max_seq_len, drop_prob):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.char_embedding = nn.Embedding(vocab_size, embed_size, padding_idx=pad_idx)\n",
    "        self.position_embedding = nn.Embedding(max_seq_len, embed_size)\n",
    "        self.LayerNorm = nn.LayerNorm(embed_size, eps=1e-7)\n",
    "        self.dropout = nn.Dropout(drop_prob)  # 0.1\n",
    "\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        position_ids = torch.arange(self.max_seq_len, dtype=torch.long, device=input_ids.device)\n",
    "        position_ids = position_ids.unsqueeze(0).expand_as(input_ids)\n",
    "\n",
    "        words_embeddings = self.char_embedding(input_ids)\n",
    "        position_embeddings = self.position_embedding(position_ids)\n",
    "        \n",
    "        embeddings = words_embeddings + position_embeddings\n",
    "        embeddings = self.LayerNorm(embeddings)\n",
    "        embeddings = self.dropout(embeddings)\n",
    "        return embeddings  # (batchSize, sequenceLength, hidden_size)\n",
    "\n",
    "class CBERT(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, dim_feedforward, num_heads, num_layers, pad_idx):\n",
    "        super(CBERT, self).__init__()\n",
    "        self.embedding_layer = EmbeddingLayer(vocab_size, embed_size, pad_idx, data_max_len, 0.1)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_size, nhead=num_heads, dim_feedforward=dim_feedforward, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.prediction_layer = nn.Linear(embed_size, vocab_size)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=2)\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        embedded_x = self.embedding_layer(x)\n",
    "        encoded_x = self.transformer_encoder(embedded_x, src_key_padding_mask=mask)\n",
    "        out = self.prediction_layer(encoded_x)\n",
    "        output = self.log_softmax(out)\n",
    "        return output\n",
    "\n",
    "def generateData(iid, mask, device='cpu'):\n",
    "    input_ids = torch.tensor(iid, device=device) # input_ids is the generated data; iid becomes target\n",
    "    rand = torch.rand(iid.shape, device=device)\n",
    "    # MASK\n",
    "    mask_mask = rand < 0.12 # 0.15*0.8\n",
    "    input_ids[mask_mask] = char_to_id['<MASK>']\n",
    "    # SWAP\n",
    "    swap_mask = rand > 1-0.015 # 0.15*0.1\n",
    "    swap_char = torch.floor(torch.rand(iid.shape) * vocab_size + num_spechar).to(dtype=torch.long, device=device) # e.g. [0,1) -> [0~3) -> [4~7) -> 4,5,6\n",
    "    input_ids[swap_mask] = swap_char[swap_mask] \n",
    "    # NOTHING (but predict)\n",
    "    same_mask = (rand>=0.12) * (rand<=0.12+0.015)\n",
    "\n",
    "    used_mask = mask_mask + swap_mask + same_mask\n",
    "    # Prevention of zero targets, which leads to nan loss\n",
    "    if torch.sum(used_mask*(mask==0))==0: \n",
    "        same_mask[0,1] = True\n",
    "        used_mask[0,1] = True\n",
    "        \n",
    "    # padding all unmasked words on target; loss function ignores <PAD>.\n",
    "    iid[torch.logical_not(used_mask)] = char_to_id['<PAD>']\n",
    "    \n",
    "    return (input_ids, iid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b918c1c-f54f-418e-8d6a-139518d93445",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, loss_f, train_iter, num_epochs, device='cpu', prnt_intv=1):\n",
    "    model = model.to(device=device)\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss_sum = torch.tensor([0.0], device=device)\n",
    "        train_acc_sum = torch.tensor([0.0], device=device)\n",
    "        num_seq = 0\n",
    "        num_pred = 0\n",
    "        for iid, mask in train_iter:\n",
    "            iid, mask = iid.to(device=device), mask.to(device=device)\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            x, y = generateData(iid, mask, device)\n",
    "            y_hat = model(x, mask)\n",
    "            y_hat = y_hat.permute([0,2,1])\n",
    "            \n",
    "            loss = loss_f(y_hat, y)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1e-5)\n",
    "            optimizer.step()\n",
    "            \n",
    "            #if not torch.isfinite(loss):\n",
    "            #    print(x, y, iid, mask)\n",
    "            with torch.no_grad():\n",
    "                train_loss_sum += loss.float()\n",
    "                pred = torch.argmax(y_hat, dim=1)\n",
    "                pred[y==0]=-1 # These are not predicted by model\n",
    "                train_acc_sum += torch.sum(pred==y)\n",
    "                num_seq += iid.shape[0]\n",
    "                num_pred += torch.sum(y!=0)\n",
    "                \n",
    "            # Debugging purposes\n",
    "            if False:\n",
    "                print(loss)\n",
    "                for i,p,t in zip(x, pred, y):\n",
    "                    print(\"INPUT:\", end=' ')\n",
    "                    print_decoded_ids(i)\n",
    "                    print(\"TARGET:\", end=' ')\n",
    "                    print_decoded_ids(t)\n",
    "                    print(\"PREDICTION:\", end=' ')\n",
    "                    print_decoded_ids(p)\n",
    "                    \n",
    "        if (epoch+1)%prnt_intv == 0:\n",
    "            print(\"Epoch:%d Loss:%f, TrainAcc:%f\"%(epoch+1,train_loss_sum/num_seq,train_acc_sum/num_pred))\n",
    "\n",
    "def evaluate(model, loss_f, val_iter, device='cpu'):\n",
    "    model = model.to(device=device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        loss_sum = torch.tensor([0.0], device=device)\n",
    "        acc_sum = torch.tensor([0.0], device=device)\n",
    "        num_seq = 0\n",
    "        num_pred = 0\n",
    "        \n",
    "        for iid, mask in val_iter:\n",
    "            iid, mask = iid.to(device=device), mask.to(device=device)\n",
    "            x, y = generateData(iid, mask, device)\n",
    "            y_hat = model(x, mask)\n",
    "            y_hat = y_hat.permute([0,2,1])\n",
    "            \n",
    "            loss = loss_f(y_hat, y)\n",
    "            \n",
    "            loss_sum += loss.float()\n",
    "            pred = torch.argmax(y_hat, dim=1)\n",
    "            pred[y==0]=-1 # These are not predicted by model\n",
    "            acc_sum += torch.sum(pred==y)\n",
    "            num_seq += iid.shape[0]\n",
    "            num_pred += torch.sum(y!=0)\n",
    "            \n",
    "        print(\"Val_Loss:%f, Val_Acc:%f\"%(loss_sum/num_seq, acc_sum/num_pred))\n",
    "            \n",
    "def print_decoded_ids(ids):\n",
    "    for c in ids:\n",
    "        if c==0: # <PAD>, <SEP>\n",
    "            print('_', end='')\n",
    "        else:\n",
    "            print(id_to_char[c], end='')\n",
    "    print()\n",
    "    \n",
    "def show_sample(model, train_iter, loss_f, device='cpu', test_iter=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for iid, mask in train_iter:\n",
    "            iid, mask = iid.to(device=device), mask.to(device=device)\n",
    "            x, y = generateData(iid, mask, device)\n",
    "            y_hat = model(x, mask)\n",
    "            y_hat = y_hat.permute([0,2,1])\n",
    "            pred = torch.argmax(y_hat, dim=1)\n",
    "            loss = loss_f(y_hat, y)\n",
    "            \n",
    "            for i,p,t in zip(x, pred, y):\n",
    "                print(\"INPUT:\", end=' ')\n",
    "                print_decoded_ids(i)\n",
    "                print(\"TARGET:\", end=' ')\n",
    "                print_decoded_ids(t)\n",
    "                print(\"PREDICTION:\", end=' ')\n",
    "                print_decoded_ids(p)\n",
    "            print(\"loss:\", loss)\n",
    "            pred = torch.argmax(y_hat, dim=1)\n",
    "            pred[y==0]=-1\n",
    "            print(\"acc:\",torch.sum(pred==y)/torch.sum(y!=0))\n",
    "            \n",
    "            break\n",
    "            \n",
    "def init_weights(layer):\n",
    "    if hasattr(layer, 'weight') and layer.weight.dim()>1:\n",
    "        torch.nn.init.xavier_uniform_(layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67ee7c8-5c43-4e05-9e1a-6ed461d25ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# Hyperparameter log #\n",
    "######################\n",
    "#\n",
    "# Data: Yelp[1:2]\n",
    "# Model: embed384, ff1024, heads12, layers6\n",
    "# Hyperparam: lr1e-5, clip1e-5\n",
    "# Epochs to reach first 1.0: 1810 / around 1400\n",
    "#\n",
    "# Data: Yelp[1:2] (same masking)\n",
    "# Model: embed64, ff256, heads8, layers6\n",
    "# Hyperparam: lr1e-5, clip1e-5\n",
    "# Epochs to reach first 1.0: 860\n",
    "#\n",
    "# Data: Yelp[1:2]\n",
    "# Model: embed64, ff256, heads8, layers6\n",
    "# Hyperparam: lr1e-5, clip1e-5\n",
    "# Epochs to reach first 1.0: failed\n",
    "#\n",
    "# Data: Yelp[1:2]\n",
    "# Model: embed128, ff512, heads8, layers6\n",
    "# Hyperparam: lr1e-5, clip1e-5\n",
    "# Epochs to reach first 1.0: more than 2000\n",
    "#\n",
    "# Data: Yelp[1:2]\n",
    "# Model: embed64, ff256, heads8, layers12\n",
    "# Hyperparam: lr1e-5, clip1e-5\n",
    "# Epochs to reach first 1.0: failed\n",
    "#\n",
    "# Data: Yelp[1:2]\n",
    "# Model: embed768, ff2048, heads12, layers6\n",
    "# Hyperparam: lr1e-5, clip1e-5\n",
    "# Epochs to reach first 1.0: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820e247c-004f-4328-8a35-f9e64223c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CBERT(vocab_size=len(id_to_char),\n",
    "                 embed_size=768,\n",
    "                 dim_feedforward=2048,\n",
    "                 num_heads=12,\n",
    "                 num_layers=6,\n",
    "                 pad_idx=char_to_id['<PAD>'])\n",
    "model.apply(init_weights)\n",
    "model = model.to(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275bad83-10b5-495d-8700-c10c0f419ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "LOADPATH = \"./models/yelp6_cp12.pt\"\n",
    "checkpoint = torch.load(LOADPATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.to(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8a539f-97e6-4879-b4f6-b4decd9d6118",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay = 0.0)\n",
    "loss_f = nn.NLLLoss(ignore_index=char_to_id['<PAD>'])\n",
    "train(model, optimizer, loss_f, train_iter, num_epochs=1, device='cuda', prnt_intv=1)\n",
    "evaluate(model, loss_f, val_iter, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8497f935-656f-47ff-b320-e69e7ac12e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    train(model, optimizer, loss_f, train_iter, num_epochs=1, device='cuda', prnt_intv=1)\n",
    "    show_sample(model, train_iter, loss_f, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac916b82-304f-4509-90d3-e9db1f97b1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay = 0.0)\n",
    "loss_f = nn.NLLLoss(ignore_index=char_to_id['<PAD>'])\n",
    "train(model, optimizer, loss_f, train_iter, num_epochs=50, device='cuda', prnt_intv=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b96dd2-7370-4ee0-b87d-bcbc7fbcdd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with model save & learning rate schedule\n",
    "lr = 5e-5\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay = 0.0)\n",
    "loss_f = nn.NLLLoss(ignore_index=char_to_id['<PAD>'])\n",
    "for i in range(100):\n",
    "    print(\"Training iter {0}, lr {1}\".format(i,lr))\n",
    "    train(model, optimizer, loss_f, train_iter, num_epochs=5, device='cuda', prnt_intv=1)\n",
    "    # Save model\n",
    "    PATH = \"./models/sample_cp\" + str(i).zfill(2) + \".pt\"\n",
    "    torch.save({\n",
    "        'model_state_dict' : model.state_dict(),\n",
    "    }, PATH)\n",
    "    evaluate(model, loss_f, val_iter, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623b1644-2f03-4131-a832-43cb578fde22",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./models/sample.pt\"\n",
    "torch.save({\n",
    "    'model_state_dict' : model.state_dict(),\n",
    "}, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14baae85-d5fd-45c1-acdd-2ecab7cb434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_f = nn.NLLLoss(ignore_index=char_to_id['<PAD>'])\n",
    "show_sample(model, val_iter, loss_f, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9058c3f5-a29a-4535-a175-4e21166f88c8",
   "metadata": {},
   "source": [
    "## *Overfitting Test*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6397f5-1c67-4513-b2aa-3a1d236912bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"===INPUT===\")\n",
    "for c in model_input[0]:\n",
    "    if(c==0): break\n",
    "    print(id_to_char[c], end='')\n",
    "print(\"\\n===TARGET===\")\n",
    "for c in target[0]:\n",
    "    if c==0:\n",
    "        print('_', end='')\n",
    "    else:\n",
    "        print(id_to_char[c], end='')\n",
    "\n",
    "# e.g.\n",
    "# ===INPUT===\n",
    "# <CLS>i have <MASK><MASK>n into th<MASK>s <MASK>ro<MASK>lem with man<MASK> other<MASK><MASK>octo<MASK>s a?d i <MASK>us<MASK> don't get<MASK><MASK><MASK>.<SEP>\n",
    "# ===TARGET===\n",
    "# ________ru_________i__p__b_________m__y______ d____r___n____j__t__________ it___________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cb5d22-4b90-46a8-a370-78c7513be6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DummyModel, self).__init__()\n",
    "        vocab_size = len(id_to_char)\n",
    "        embed_size = 768 # same as BERT\n",
    "        pad_idx = char_to_id['<PAD>']\n",
    "        self.embedding_layer = nn.Embedding(vocab_size, embed_size, padding_idx=pad_idx)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_size, nhead=8, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
    "        self.prediction_layer = nn.Linear(embed_size, vocab_size)\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        embedded_x = self.embedding_layer(x)\n",
    "        encoded_x = self.transformer_encoder(embedded_x, src_key_padding_mask=mask)\n",
    "        output = self.prediction_layer(encoded_x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a054946e-0c50-4deb-962b-e386bc94e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = DummyModel()\n",
    "optimizer = optim.Adam(dummy_model.parameters(), lr=1e-3, weight_decay = 0.0)\n",
    "loss_f = nn.NLLLoss(ignore_index=char_to_id['<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b67e34-7b20-4cf6-a0e1-6d630c9495d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = input_ids\n",
    "test_mask = encoder_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76122bde-16c5-45d2-a2ee-e2f25b892d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    optimizer.zero_grad()\n",
    "    test_output = dummy_model(test_input, test_mask)\n",
    "    pred_output = test_output.permute([0,2,1])\n",
    "    train_mask = torch.ones(test_input.shape, dtype=torch.long)\n",
    "    train_mask[:,2] = 0 # Prevent model from learning index 2\n",
    "    target = test_input*train_mask\n",
    "    loss = loss_f(pred_output, target)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f934fbf-25c2-41cc-b1d6-7e8ea3007d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "test_output = dummy_model(test_input, test_mask)\n",
    "pred_output = test_output.permute([0,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4f681c-bdff-4a22-a941-70105be4a52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = torch.argmax(pred_output,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6230dd59-d140-47f7-9669-268e6cf7c9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_output[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9932f9fc-ff47-40fa-8d3e-17114a943529",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_input.shape)\n",
    "print(result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9975f230-7ae4-4462-a590-c60b0b3f4eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(input_ids[2])\n",
    "print(encoder_mask[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6beef3-7724-4337-8b77-12a725bcdf87",
   "metadata": {},
   "source": [
    "## *Below are not used*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79ecf12-3eb4-4e33-8de4-ae3c622c19de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e014065c-2200-4104-af75-c8bf5383cf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_data = []\n",
    "for text in train_yelp_data['text']:\n",
    "    text = text.lower()\n",
    "    i = 0\n",
    "    for j, c in enumerate(text):\n",
    "        if i==j and c==' ':\n",
    "            i+=1\n",
    "        if c in ['.','?','!']:\n",
    "            if j-i>1:\n",
    "                refined_data.append(text[i:j])\n",
    "            i=j+1\n",
    "print(len(refined_data))\n",
    "#print(refined_data)\n",
    "\n",
    "space = \"<SPACE>\"\n",
    "data = []\n",
    "for sentence in refined_data:\n",
    "    d = [\"<CLS>\"]\n",
    "    for c in sentence:\n",
    "        if c == ' ':\n",
    "            d.append(space)\n",
    "        else:\n",
    "            d.append(c)\n",
    "    d.append(\"<SEP>\")\n",
    "    data.append(d)\n",
    "    \n",
    "input_ids = []\n",
    "for sentence in data:\n",
    "    d = [char_to_id[c] for c in sentence]\n",
    "    input_ids.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c875598-b724-4c9c-939b-3f032f9445f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For overfitting\n",
    "# Took me 3days to overfit a SINGLE sentence with the SAME masking :)\n",
    "def generateData(iid, mask, device='cpu'):\n",
    "    input_ids = iid.clone().detach().to(device=device) # input_ids is the generated data; iid becomes target\n",
    "    rand = torch.rand(iid.shape, device=device)\n",
    "    # MASK\n",
    "    mask_mask = [0]*256\n",
    "    for i in [1,3,6,8,10,15,18,20,25,30,49]:\n",
    "        mask_mask[i] = 1\n",
    "    mask_mask = torch.tensor([mask_mask])\n",
    "    mask_mask = mask_mask>=1\n",
    "    input_ids[mask_mask] = char_to_id['<MASK>']\n",
    "    \n",
    "    used_mask = mask_mask\n",
    "    iid[torch.logical_not(used_mask)] = char_to_id['<PAD>']\n",
    "    \n",
    "    return (input_ids, iid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
