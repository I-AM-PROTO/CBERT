{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d95b3e4-1063-48c1-88b3-d7f990d72e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3851b08-849d-4e95-81f2-ce2a32112562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"SetFit/sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffd5888-355c-43d7-b054-6b639ee06fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import datasets\n",
    "import numpy as np\n",
    "import random\n",
    "from transformers import Trainer\n",
    "from datasets import load_metric\n",
    "metric = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61fe7be-d5e9-4d9b-9d68-45195a120e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_char = ['<PAD>', '<CLS>', '<SEP>', '<MASK>', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '@', \\\n",
    "              '[', '\\\\', ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~']\n",
    "char_to_id = {c:i for i,c in enumerate(id_to_char)}\n",
    "chars = [' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '@', '[', '\\\\', ']', \\\n",
    "         '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '{', '|', '}', '~']\n",
    "rep = ['-lrb-', '-rrb-', 'ã§', 'ã¯', 'ã£', 'ã¨', 'ã»', 'ã¶', 'ã±', 'ã¢', 'ã-', 'ã¡', 'ã¦', 'ã³', 'ã©', 'ã¼', 'ü', 'û', 'ñ', 'ó', 'ô', 'ö', 'í', 'ï', 'mollã', 'jirã', 'ã', '\\xad', '¼', '³', '¡', '¦', '\\xa0', '¢', 'ç', '´', 'à', 'á', 'â', 'é', 'è', 'æ' ]\n",
    "tok = ['('    , ')'    , 'c' , 'i' , 'a' , 'e' , 'u' , 'o' , 'n' , 'a' , 'i' , 'a' , 'ae', 'o' , 'e' , 'u' , 'u', 'u', 'n', 'o', 'o', 'o', 'i', 'i', 'molla', 'jiri', 'a', ''    , '' , '' , '' , '' , ''    , 'c', 'c', '' , 'a', 'a', 'a', 'e', 'e', 'ae']\n",
    "assert(len(rep)==len(tok))\n",
    "\n",
    "num_replace = 1\n",
    "num_mod = 1\n",
    "global_seed = 1\n",
    "\n",
    "def gen_adv(examples):\n",
    "    ret = []\n",
    "    np.random.seed(global_seed)\n",
    "    random.seed(global_seed)\n",
    "    for text in examples['text']:\n",
    "        text = refine_sentence(text)\n",
    "        text = list(text)\n",
    "        \n",
    "        rpl = random.random() \n",
    "        ins = random.random()\n",
    "        rmv = random.random()\n",
    "        rpl = rpl/(rpl+ins+rmv)\n",
    "        ins = ins/(rpl+ins+rmv)\n",
    "        rpl = math.floor(num_mod*rpl)\n",
    "        ins = math.floor(num_mod*ins)\n",
    "        rmv = num_mod - rpl - ins\n",
    "        \n",
    "        #remove\n",
    "        rnd = np.random.permutation(len(text))[:rmv]\n",
    "        rnd *= -1\n",
    "        rnd.sort()\n",
    "        rnd *= -1\n",
    "        for i in rnd:\n",
    "            del text[i]\n",
    "        \n",
    "        #replace\n",
    "        rnd = np.random.permutation(len(text))[:rpl]\n",
    "        for i in rnd:\n",
    "            text[i] = random.choice(chars)\n",
    "        \n",
    "        #insert\n",
    "        rnd = np.random.permutation(len(text))[:ins]\n",
    "        rnd *= -1\n",
    "        rnd.sort()\n",
    "        rnd *= -1\n",
    "        for i in rnd:\n",
    "            text.insert(i, random.choice(chars))\n",
    "            \n",
    "        ret.append(''.join(text))\n",
    "    return {'text':ret}\n",
    "\n",
    "def refine_sentence(sent):\n",
    "    sent = sent.lower()\n",
    "    # Cut out \\n|\n",
    "    if sent[-1]=='\\n': sent=sent[:-1]\n",
    "    # Repleace LRB, RRB to (, ) respectively\n",
    "    for f, t in zip(rep, tok):\n",
    "        sent = sent.replace(f, t)\n",
    "    return sent\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", max_length=128, truncation=True)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "trainer = Trainer(model=model, compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b18bcb-f16a-4d8a-9956-8a9aea2800a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A very lazy evaluation algorithm :)\n",
    "seeds = [31, 41, 59, 2, 65, 35, 897, 93, 2384, 626]\n",
    "val_result = []\n",
    "test_result = []\n",
    "for n_r in range(11):\n",
    "    num_mod = n_r\n",
    "    val_rt = []\n",
    "    test_rt = []\n",
    "    for seed in seeds:\n",
    "        global_seed = seed\n",
    "        replaced_dataset = dataset.map(gen_adv, batched=True)\n",
    "        replaced_dataset = replaced_dataset.map(tokenize_function, batched=True)\n",
    "        val_r = trainer.evaluate(replaced_dataset['validation'])\n",
    "        test_r = trainer.evaluate(replaced_dataset['test'])\n",
    "        val_rt.append(val_r)\n",
    "        test_rt.append(test_r)\n",
    "    val_result.append(val_rt)\n",
    "    test_result.append(test_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af2fa51-4ac9-4e46-bdb9-3c9e169f486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print result\n",
    "for k in range(11):\n",
    "    print(k)\n",
    "    avg = 0.0\n",
    "    for r in val_result[k]:\n",
    "        print(r['eval_accuracy'], end=' ')\n",
    "        avg += r['eval_accuracy']\n",
    "    print(\"AVG: \", avg/len(val_result[k]))\n",
    "print(\"=\"*80)\n",
    "for k in range(11):\n",
    "    print(k)\n",
    "    avg = 0.0\n",
    "    for r in test_result[k]:\n",
    "        print(r['eval_accuracy'], end=' ')\n",
    "        avg += r['eval_accuracy']\n",
    "    print(\"AVG: \", avg/len(val_result[k]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
